{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zaawansowane sieci neuronowe w detekcji sentymentu\n",
    "\n",
    "Na dzisiejszych laboratoriach skupimy się na wykorzystaniu zaawansowanych architektur sieci neuronowych do problemu wykrywania sentymentu (emocji: pozytywnych i negatywnych), które zawarte są w tekstach.\n",
    "\n",
    "Ponieważ implementacja sieci LSTM i GRU jest dość trudna/czasochłonna - wykorzystamy gotowy framework, który pozwoli nam na zdefiniowanie i wyuczenie sieci neuronowej na wysokim poziomie - **Keras**.\n",
    "\n",
    "Ocenę sentymentu przeprowadzimy na gotowym zbiorze recenzji z portalu IMDB, który jest już odpowiednio przeprocesowany i posiada zdefiniowany oczekiwany sentyment dla każdego tekstu (a więc dla którego bez wysiłku możemy uruchomić algorytmy klasyfikacji i je ocenić). Zaczynajmy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane do uczenia\n",
    "\n",
    "Poniższy fragment kodu pobiera dane do uczenia. Funkcja imdb.load_data() ładuje zarówno zbiór uczący (wektory cech, oraz etykiety), jak i analogiczny zbiór testowy. \n",
    "\n",
    "Poniżej wyświetlony na ekranie jest jeden z przykładów uczących oraz przypisana do niego etykieta.\n",
    "\n",
    "Widzimy, że tekst reprezentowany jest sekwencją liczb. Co one oznaczają?\n",
    "Każda liczba reprezentuje słowo (jest identyfikatorem słowa), identyfikatory posortowane są względem częstości występowania słów, zatem słowo o identyfikatorze 10 występuje w korpusie częśćiej niż słowo o identyfikatorze 11.\n",
    "Dodatkowo wprowadzone są specjalne znaczniki BOS - początek zdania i EOS - koniec zdania. Oba równiez reprezentowane są w formie liczbowej.\n",
    "\n",
    "Pamiętamy z jednych z pierwszych laboratoriów, że duża wielkość słownika jest problematyczna. Dobrym pomysłem jest często odrzucenie najrzadziej wystepujących słów, ponieważ one nie mają wielkiego znaczenia (Kiedy uczymy się nowego języka - często nie rozumiemy pojedynczych słów, ale znajomość pozostałych sprawia, że jesteśmy w stanie zrozumieć sens tekstu). Aby ograniczyć rozmiar słownika, w funkcji load_data() możemy zadać parametr num_words o określonej wartości. Wartość ta, mówi nam ile najczęściej występujących słów bierzemy pod uwagę. Wszystkie rzadsze słowa - reprezentowane są zbiorczo taką samą wartością liczbową oznaczającą nieznany token (Unknown token).\n",
    "\n",
    "Inną ważną kwestią jest długość recenzji - każda z nich może składać się z innej liczby słów. O ile sieci rekurencyjne są teoretycznie w stanie poradzić sobie z sekwencjami o różnej długości, to w praktyce optymalizacje wymagają, aby sekwencje były reprezentowane poprzez taką samą długość wektora cech. Aby wyrównać liczbę cech na wejściu stosuje się tzw. padding do określonej długości. Jeśli wektor cech recenzji jest dłuższy niż zadany padding - zostaje on ucięty, jeśli zaś jest krótszy - dodawane są cechy o wartości 0, aby dopełnić długości.\n",
    "\n",
    "**Zadanie 1 (1.25 punktu)**: Poniższy kod pobiera dane z IMDB ograniczając liczbę słów w słowniku do 10000. \n",
    "Chcielibyśmy przyjrzeć się danym oraz zastosować na nich padding. Aby to zrobić - wykonajmy następujące kroki:\n",
    "<ol>\n",
    "    <li>Sprawdźmy i wyświetlmy średnią długość wektora w x_train - pozwoli nam to sprawdzić ile średnio słów jest w recenzji</li>\n",
    "    <li>Sprawdźmy i wyświetlmy odchylenie standardowe wektora x_train - pozwoli nam to określić jak wygląda rozrzut wartości od średniej</li>\n",
    "    <li>Stosując funkcję pad_sequences z kerasa (zaimportowana w pierwszej linijce) - nadpiszmy zbiory x_train i x_test tak, aby każdy wektor miał długość 500 (https://keras.io/preprocessing/sequence/). Wybrana długość wynika z analizy z poprzednich podpunktów (średnia i odch. std.). Jak teraz wygląda średnia długość i odchylenie std?</li>\n",
    "    <li>Nasz model będziemy weryfikować na zbiorze testowym z użyciem miary accuracy (jaki % podjętych przez klasyfikator decyzji jest poprawnych). Warto sprawdzić jak wygląda rozkład etykiet w zbiorze testowym. Sprawdź: jaki procent zbioru testowego stanowią etykiety o wartości 1? jaki procent zbioru testowego stanowią etykiety o wartości 0?\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 1205925.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n",
      "@1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 631409.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przed paddingiem. Średnia długość wektora: 238.71364; odchylenie std: 176.49367364852034\n",
      "Po paddingu. Średnia długość wektora: 500.0; odchylenie std: 0.0\n",
      "W zbiorze testowym jest 12500 elementów o pozytywnym sentymencie i 12500 elementów o negatywnym. Sentyment pozytywny stanowi 50.0% zbioru.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "print(x_train[0]) # pokaż wektor cech dla pierwszej recenzji\n",
    "print(y_train[0]) # pokaż etykietę (1 = sentyment pozytywny; 0 = sentyment negatywny)\n",
    "\n",
    "print(\"@1\")\n",
    "shapes = [len(x) for x in tqdm(x_train)]\n",
    "average_x_len = np.mean(shapes) # TODO: oblicz średnią liczbę cech w wektorach x_train (możesz wykorzystać numpy)\n",
    "stddev_x_len = np.std(shapes) # TODO: oblicz odchylenie standardowe po x_train (możesz wykorzystać numpy)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=500) # TODO: zastosuj padding do 500 tokenów (wskazówka: zobacz na listę importowanych funkcji)\n",
    "x_test = pad_sequences(x_test, maxlen=500)   # TODO: zastosuj padding do 500 tokenów\n",
    "\n",
    "print(\"@2\")\n",
    "padded_shapes = [len(x) for x in tqdm(x_train)]\n",
    "padded_average_x_len = np.mean(padded_shapes) # TODO: oblicz średnią liczbę cech w wektorach x_train po paddingu\n",
    "padded_stddev_x_len = np.std(padded_shapes) # TODO: oblicz odchylenie standardowe po x_train po paddingu\n",
    "\n",
    "#--------------\n",
    "import matplotlib.pyplot as plt\n",
    "n_bins = 20\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "axs[0].hist(shapes, bins=n_bins)\n",
    "axs[1].hist(padded_shapes, bins=n_bins)\n",
    "plt.show()\n",
    "#--------------\n",
    "\n",
    "count_positive = (y_test == 1).sum()  # TODO: ile elementów testowych ma przypisany sentyment pozytywny\n",
    "count_negative = (y_test == 0).sum()  # TODO: ile elementów testowych ma przypisany sentyment negatywny\n",
    "\n",
    "print(\"Przed paddingiem. Średnia długość wektora: {ave_len}; odchylenie std: {std_dev}\".format(\n",
    "    ave_len=average_x_len, std_dev=stddev_x_len))\n",
    "\n",
    "print(\"Po paddingu. Średnia długość wektora: {ave_len}; odchylenie std: {std_dev}\".format(\n",
    "    ave_len=padded_average_x_len, std_dev=padded_stddev_x_len))\n",
    "\n",
    "print(\"W zbiorze testowym jest {pos} elementów o pozytywnym sentymencie i {neg} elementów o negatywnym. Sentyment pozytywny stanowi {percentage}% zbioru.\".format(\n",
    "pos=count_positive, neg=count_negative, percentage = 100.0*(count_positive)/(count_positive + count_negative)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykładowa prosta sieć w Keras.\n",
    "Poniżej znajdziecie przykład kodu, którzy tworzy sieć dwuwarstwową o:\n",
    "<ol>\n",
    "<li>100 wejściach</li>\n",
    "<li>warstwie ukrytej z 64 neuronami o aktywacji ReLU</li>\n",
    "<li>warstwie wyjściowej z 1 neuronem o aktywacji sigmoidalnej</li>\n",
    "</ol>\n",
    "Ten kod będzie szablonem dla kolejnych zdań. Uruchom go i sprawdź jak prosta sieć działa \n",
    "\n",
    "$ReLU(x) = max(0, x)$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 4s 148us/sample - loss: 73.4402 - accuracy: 0.4994 - val_loss: 4.3048 - val_accuracy: 0.4959\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 3s 128us/sample - loss: 1.9936 - accuracy: 0.5065 - val_loss: 1.5232 - val_accuracy: 0.4996\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 3s 123us/sample - loss: 0.9284 - accuracy: 0.5074 - val_loss: 1.1877 - val_accuracy: 0.5007\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 3s 125us/sample - loss: 0.7556 - accuracy: 0.5157 - val_loss: 1.0535 - val_accuracy: 0.5005\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 3s 123us/sample - loss: 0.7185 - accuracy: 0.5099 - val_loss: 1.0264 - val_accuracy: 0.5049\n",
      "25000/25000 [==============================] - 0s 15us/sample - loss: 1.0264 - accuracy: 0.5049\n",
      "Trafność klasyfikacji to: 50.492000579833984%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, LSTM, GRU, Conv1D, MaxPooling1D\n",
    "\n",
    "\n",
    "model = Sequential() \n",
    "# sequential = sieć jako lista warstw, dodajemy warstwy metodą .add() (jak w standardowej liście)\n",
    "model.add(Dense(units=64, input_dim=500, activation='relu'))\n",
    "# dodajemy warstwę Dense (gęstą). Dense oznacza, że wszystkie wejścia (w tym przypadku 100) \n",
    "# połączone są z neuronami warstwy w sposób każdy z każdym (każdy neuron z poprzedniej warstwy \n",
    "# połączony z każdym neuronem warstwy następnej, tak jak to robiliśmy na poprzednich laboratoriach)\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "# rozmiar wejścia zdefiniować musimy tylko w pierwszej warstwie (definiujemy ile jest cech na wejściu).\n",
    "# Ponieważ model wie jakie są rozmiary poprzednich warstw - może w sposób automatyczny odkryć, że \n",
    "# opprzednia warstwa generuje 64 wyjścia\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # budujemy model! ustawiamy funkcję kosztu - mamy klasyfikację z dwiema etykietami,\n",
    "              # więc stosujemy 'binary_crossentropy'\n",
    "              optimizer='adam', \n",
    "              # wybieramy w jaki sposób sieć ma się uczyć\n",
    "              metrics=['accuracy'])\n",
    "              # i wybieramy jaka miara oceny nas interesuje\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test)) # uczymy model na zbiorze treningowym, weryfikujemy na testowym, epochs - oznacza ile przejść po wszystkich przykładachw zbiorze uczącym powinno się wykonać.\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test, batch_size=128) # ostateczna ewaluacja wyuczonego modelu\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy, sieć generuje trafność na poziomie 50%. Ponieważ zarówno etykieta \"1\", jak i \"0\" w zbiorze testowym stanowią połowę - wiemy, że ten klasyfikator nie jest najlepszy (Taką samą trafność będą miały klasyfikatory: zwracające zawsze etykietę 0, zwracajace zawsze etykietę 1 oraz zwracające decyzje losowe).\n",
    "\n",
    "Czy jesteśmy w stanie coś z tym zrobić? \n",
    "Tak. Nasza poprzednia sieć próbowała uczyć się z listy identyfikatorów słów, to stosunkowo kiepska reprezentacja, ale pamiętamy, że całkiem nieźle sprawowały się tzw. Embeddingi. Szczęśliwie - keras udostępnia warstwy uczące się embeddingów z reprezentacji takiej, którą dotychczas podawaliśmy na wejściu.\n",
    "\n",
    "\n",
    "\n",
    "**Zadanie 2 (1.25 punktu) - Wykorzystanie embeddingów w sieci feed forward**\n",
    "Widząc w jaki sposób dodawane są kolejne warstwy w Kerasie (model.add(...)), przerób architekturę istniejącej sieci w następujący sposób:\n",
    "\n",
    "<ol>\n",
    "    <li>Pierwsza warstwa: Warstwa Embedding (https://keras.io/layers/embeddings/), ustaw długość generowanego wektora na 32, długość wejścia - taka jak wynika to z paddingu - 500, a także rozmiar słownika zgodny z tym co wybraliśmy przy pobieraniu danych (10000)</li>\n",
    "    <li>Druga warstwa: Flatten (https://keras.io/layers/core/); Zauważmy, że warstwa ucząca embeddingi - Embedding - zamienia nam każdy indentyfikator z wektora wejściowego na wektor o zadanej liczbie wymiarów. Każde słowo reprezentowane jest teraz nie pojedynczą liczbą a pojedynczym wektorem. Kiedy złożymy embeddingi wszystkich słów otrzymamy macierz wielkości: liczba słów x rozmiar embeddingu. Warstwa Flatten nie robi nic poza tym, że bierze taką macierz i zamienia znów na wektor poprzez połączenie ze sobą wszystkich wektorów embeddingów w jeden wielki wektor (ustawiając je w jednym wymiarze jeden za drugim) </li>\n",
    "    <li>Trzecia warstwa: klasyczna warstwa Dense (https://keras.io/layers/core/) np. z 64 neuronami i aktywacją relu\n",
    "    <li>Czwarta warstwa (wyjściowa): klasyczna warstwa Dense z 1 neuronem (generującym prawdopodobieństwo pozytywnego sentymentu) i aktywacją sigmoidalną (sigmoid)\n",
    "</ol>\n",
    "Parametry kompilacji, sposób uczenia i ewaluacji możesz pozostawić bez zmian. Czy trafność klasyfikacji wzrosła?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 12s 472us/sample - loss: 0.4532 - accuracy: 0.7675 - val_loss: 0.2854 - val_accuracy: 0.8783\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 11s 454us/sample - loss: 0.1575 - accuracy: 0.9429 - val_loss: 0.2997 - val_accuracy: 0.8757\n",
      "25000/25000 [==============================] - 4s 170us/sample - loss: 0.2997 - accuracy: 0.8757\n",
      "Trafność klasyfikacji to: 87.57200241088867%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, 32, input_length=500))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architektury rekurencyjne\n",
    "\n",
    "Aby zamodelować sieć rekurencyjną LSTM bądź GRU - możemy użyć dedykowanych warstw przygotowanych przez autorów Kerasa.\n",
    "\n",
    "\n",
    "**Zadanie 3 (1.25 punktu): Sieć rekurencyjna GRU i LSTM**\n",
    "Aby stworzyć taką sieć utwórz model z następującymi warstwami:\n",
    "\n",
    "<ol>\n",
    "    <li>Warstwa Embedding, analogicznie do poprzednich zadań. Rozmiar wektora embeddingów ustawmy na 32</li>\n",
    "    <li>Warstwa LSTM (https://keras.io/layers/recurrent/) - Warstwa sieci rekurencyjnej - nie potrzebuje wcześniejszego spłaszczenia warstwą Flatten. Ustawmy rozmiar tej warstwy na 32. Ponadto ustawmy parametry dropout i recurrent_dropout na 0.2 (parametr regularyzacyjny zabezpieczający przet przeuczeniem)</li>\n",
    "    <li>Warstwa Dense (wyjściowa) - Warstwa o aktywacji sigmoidalnej z 1 neuronem</li>\n",
    "</ol>\n",
    "\n",
    "Po uruchomieniu sieci wykorzystującej LSTM - zamień warstwę LSTM na GRU (https://keras.io/layers/recurrent/) z takimi samymi parametrami - czy sieć uczy się lepiej? Co z czasem uczenia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 121s 5ms/sample - loss: 0.5073 - accuracy: 0.7372 - val_loss: 0.3384 - val_accuracy: 0.8568\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 129s 5ms/sample - loss: 0.2957 - accuracy: 0.8785 - val_loss: 0.3355 - val_accuracy: 0.8599\n",
      "25000/25000 [==============================] - 56s 2ms/sample - loss: 0.3355 - accuracy: 0.8599\n",
      "Trafność klasyfikacji to: 85.98799705505371%\n",
      "Czas treningu: 250.38144612312317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, 32, input_length=500))\n",
    "\n",
    "# ver 1.\n",
    "# model.add(LSTM(32))\n",
    "\n",
    "# ver 2.\n",
    "model.add(GRU(32))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n",
    "end_time = time.time()\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) \n",
    "print(\"Czas treningu: {t}\".format(t=end_time - start_time))\n",
    "\n",
    "\n",
    "# ODP. ===================================\n",
    "\n",
    "\"\"\"\n",
    "Train on 25000 samples, validate on 25000 samples\n",
    "Epoch 1/2\n",
    "25000/25000 [==============================] - 120s 5ms/sample - loss: 0.5323 - accuracy: 0.7410 - val_loss: 0.3833 - val_accuracy: 0.8321\n",
    "Epoch 2/2\n",
    "25000/25000 [==============================] - 119s 5ms/sample - loss: 0.2841 - accuracy: 0.8862 - val_loss: 0.3129 - val_accuracy: 0.8696\n",
    "25000/25000 [==============================] - 55s 2ms/sample - loss: 0.3129 - accuracy: 0.8696\n",
    "Trafność klasyfikacji to: 86.95600032806396%\n",
    "Czas treningu: 238.74054670333862\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Train on 25000 samples, validate on 25000 samples\n",
    "Epoch 1/2\n",
    "25000/25000 [==============================] - 121s 5ms/sample - loss: 0.5073 - accuracy: 0.7372 - val_loss: 0.3384 - val_accuracy: 0.8568\n",
    "Epoch 2/2\n",
    "25000/25000 [==============================] - 129s 5ms/sample - loss: 0.2957 - accuracy: 0.8785 - val_loss: 0.3355 - val_accuracy: 0.8599\n",
    "25000/25000 [==============================] - 56s 2ms/sample - loss: 0.3355 - accuracy: 0.8599\n",
    "Trafność klasyfikacji to: 85.98799705505371%\n",
    "Czas treningu: 250.38144612312317\n",
    "\"\"\"\n",
    "\n",
    "# LSTM: lepsze val acc. (86.95%)  --- roznica ---\n",
    "# GRU:  gorsze val acc. (85.98)   ---     1%  ---\n",
    "#\n",
    "# --> GRU powinnien sie szybciej uczyc ale dla takiej architektury i \n",
    "#     wielkosci danych nie bedzie duzej roznicy\n",
    "#     dodatkowo na GPU roznicej bylyby bardziej wyrazne\n",
    "#     (ja trenuje na CPU na laptopie ;-()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy siec rekurencyjna daje niższe rezultaty niż sieć feedforward. Dlaczego? \n",
    "Sieci rekurencyjne (LSTM i GRU) dają w wielu zadaniach wyniki, które są najlepsze możliwe. Jednakże trening takiej sieci trwa bardzo długo. Gdybyśmy odpowiednio dobrali liczbę warstw i parametry sieci - prawdopodobnie otrzymalibyśmy najlepsze rezultaty ze wsystkich porównywanych architektur - niestety za cenę czasu, który na laboratoriach jest ograniczony.\n",
    "\n",
    "Ponieważ obliczenia w niektórych architekturach są bardzo intensywne, bardzo popularnym jest wykonywanie tych obliczeń nie na procesorze, a na karcie graficznej. W przypadku posiadania dobrej karty graficznej, szybkość przetwarzania będzie dużo większa.\n",
    "\n",
    "## Architektury konwolucyjne\n",
    "\n",
    "Sieci konwolucyjne w Kerasie zostały już wykorzystane na laboratoriach ze sztucznej inteligencji. Wtedy - używaliśmy ich do detekcji czy obrazek przedstawiony na wejściu sieci reprezentował kota czy psa.\n",
    "\n",
    "Okazuje się, że problemach klasyfikacji tekstu sieci konwolucyjne (CNN - convolutional neural network) radzą sobie również bardzo dobrze (dają niezłe rezultaty, a czas ich uczenia jest zazwyczaj dużo niższy niż sieci rekurencyjnych)!\n",
    "\n",
    "Sprawdźmy jakie rezultaty otrzymamy zaprzęgając sieć konwolucyjną do naszego problemu:\n",
    "\n",
    "**Zadanie 4 (1.25 punktu)**: Przygotuj sieć konwolucyjną wg. następującego schematu:\n",
    "<ol>\n",
    "    <li>Warstwa pierwsza - Warstwa Embedding, analogiczna do poprzednich zadań </li>\n",
    "    <li>Warstwa druga - konwolucja jednowymiarowa. Użyj warstwy Conv1D (https://keras.io/layers/convolutional/) używając 32 filtrów, rozmiaru tzw. kernela = 3, padding ustawmy na 'same', a jako funkcję aktywacji 'relu' </li>\n",
    "    <li>Warstwa trzecia - MaxPooling1D (https://keras.io/layers/convolutional/), ustawmy rozmiar pool_size na 2 </li>\n",
    "    <li>Warstwa czwarta - Flatten - Znów - zamieniamy macierz będącą efektem operacji konwolucji na wektor </li>\n",
    "    <li>Warstwa piąta - Dense, 250 neuronów z aktywacją relu</li>\n",
    "    <li>Warstwa szósta (wyjściowa) - Dense, 1 neuron wyjściowy z aktywacją sigmoidalną (sigmoid)</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 35s 1ms/sample - loss: 0.4525 - accuracy: 0.7596 - val_loss: 0.2723 - val_accuracy: 0.8876\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 35s 1ms/sample - loss: 0.1883 - accuracy: 0.9287 - val_loss: 0.2829 - val_accuracy: 0.8864\n",
      "25000/25000 [==============================] - 11s 450us/sample - loss: 0.2829 - accuracy: 0.8864\n",
      "Trafność klasyfikacji to: 88.63599896430969%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, 32, input_length=500))\n",
    "model.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=250, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hurra! mamy lepszy rezultat niz LSTM czy tez GRU ale moze to wynikac tylko dlatego ze trenowalismy 2 epoche"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
